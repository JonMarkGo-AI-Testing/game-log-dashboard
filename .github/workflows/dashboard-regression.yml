name: Dashboard Regression Check

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      # Only trigger on dashboard-related files
      - 'src/components/LogDashboard.tsx'
      - 'src/components/logs/**'
      - 'src/utils/logUtils.ts'
      - 'src/hooks/useGameLogs.ts'
      - 'tests/components/LogDashboard.test.tsx'
      - 'tests/logs/**'
      - 'tests/utils/logUtils.test.ts'

permissions:
  contents: read
  pull-requests: write

jobs:
  check-dashboard-regression:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm install

      - name: Run Dashboard Tests
        id: test-run
        run: |
          # Run tests WITHOUT updating snapshots to catch mismatches
          npm test -- --testPathPattern='(LogDashboard|LogEntry|ErrorDistribution|logUtils)' --json --outputFile=test-results.json || true
          
          # If there are snapshot failures, run again with --updateSnapshot to see the differences
          if grep -q "snapshot" test-results.json; then
            echo "Snapshot failures detected. Analyzing differences..."
            # Run update snapshot in dry-run mode to see what would change
            npm test -- --testPathPattern='(LogDashboard|LogEntry|ErrorDistribution|logUtils)' -u --dry-run > snapshot-diff.txt 2>&1 || true
            
            # Save the snapshot differences
            echo "SNAPSHOT_DIFF<<EOF" >> $GITHUB_ENV
            cat snapshot-diff.txt >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          fi

          # Save test results for Devin to analyze
          TEST_RESULTS=$(cat test-results.json | jq -c . | jq -R .)
          echo "results=$TEST_RESULTS" >> $GITHUB_OUTPUT

      - name: Create Devin Review Session
        id: devin-review
        env:
          DEVIN_API_KEY: ${{ secrets.DEVIN_API_KEY }}
          TEST_RESULTS: ${{ steps.test-run.outputs.results }}
          
          REVIEW_PROMPT: |
            You are Dashboard Regression Analyzer Devin. Your task is to analyze potential regressions in the game logging dashboard. This dashboard shows events across multiple games (Tetris, Dominoes, Checkers, Snake).

            Analysis Steps:
            1. Clone the repository and prevent any pushes using a pre-push hook for safety.
            
            2. Analyze the test results JSON for failures, focusing on:
               - Failed assertions
               - Snapshot mismatches
               - Test error messages
            
            3. For snapshot failures:
               a. Review the snapshot differences in the test output
               b. Identify patterns in the differences (e.g., data formatting, layout changes)
               c. Look at the PR changes that caused these differences
               d. Determine if changes are intentional improvements or actual regressions
            
            4. Check for common dashboard regression categories:
               - Data Display:
                 * Timestamp handling and formatting
                 * Number/metric formatting
                 * Data truncation issues
                 * Tooltip content and behavior
               - Visualization:
                 * Chart/graph rendering
                 * Error distribution display
                 * Log entry layout and formatting
               - Functionality:
                 * Filtering and sorting
                 * Log processing and transformation
                 * Error handling
                 * Data loading and updates
            
            5. For each identified regression:
               a. Locate the exact component and line causing the issue
               b. Analyze the surrounding context and related changes
               c. Propose a fix that matches existing patterns in the codebase
               d. Explain the regression's impact on dashboard functionality
            
            Rules:
            1. Never create new PRs - only analyze existing ones
            2. Never commit or push changes - only review and comment
            3. When finding issues, add comments directly on the PR using the suggestion format:
               ```suggestion
               your code here
               ```
            4. Each comment should explain:
               - Why the change is needed
               - Its impact on the dashboard
               - How it relates to existing code patterns
            5. Focus on one issue per comment
            6. Use inline comments with specific line references
            7. Include code snippets in markdown format
            8. Check for duplicate comments before posting
            9. Consolidate similar issues into one comprehensive comment
            10. Work autonomously without asking for confirmation

            When suggesting fixes:
            1. Analyze the codebase to understand existing patterns
            2. Look for similar code elsewhere in the project
            3. Make suggestions that maintain consistency
            4. Explain the reasoning behind each suggestion
            5. Consider the broader impact on the dashboard
            6. Focus on maintaining existing functionality
            7. Preserve data accuracy and display consistency

            Test Results to analyze:
            ${{ steps.test-run.outputs.results }}

            Snapshot Differences (if any):
            ${{ env.SNAPSHOT_DIFF }}
        run: |
          # Convert multiline string to JSON-safe format
          ESCAPED_PROMPT=$(echo "$REVIEW_PROMPT" | jq -Rs .)

          # Make the API call to Devin
          RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $DEVIN_API_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"prompt\": $ESCAPED_PROMPT}" \
            "https://api.devin.ai/v1/sessions")

          # Debug: Print the raw response
          echo "Raw Devin Response:"
          echo "$RESPONSE"

          # Extract session details
          SESSION_ID=$(echo "$RESPONSE" | jq -r '.session_id // empty')
          if [ -z "$SESSION_ID" ] || [ "$SESSION_ID" = "null" ]; then
            echo "Error: Failed to get valid session ID from response"
            echo "Response was: $RESPONSE"
            exit 1
          fi

          echo "session-id=$SESSION_ID" >> $GITHUB_OUTPUT